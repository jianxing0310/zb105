{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "Loading model cost 0.444 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.444 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 花了 4032.22000003 s\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Word2Vec as w2v\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "\n",
    "tStart=time.time() #計算所需時間(計時開始)\n",
    "\n",
    "jieba.set_dictionary('E:/text_mining/dict.txt')  #切換至中文繁體字庫\n",
    "jieba.load_userdict('E:/text_mining/dict_keyw.txt')  #\n",
    "jieba.load_userdict('E:/text_mining/dict_cbdic.txt')  #\n",
    "\n",
    "stoplist = []\n",
    "documents =[]\n",
    "words=[]\n",
    "client = MongoClient() #預設連接自己主機上的mongodb\n",
    "database = client[\"test\"] # SQL: Database Name\n",
    "collection = database[\"news\"]\n",
    "\n",
    "with io.open('E:/text_mining/stop_words.txt','r',encoding = 'utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        stoplist.append(line.strip('\\n'))\n",
    "for post in collection.find():\n",
    "    documents.append(post['content'])\n",
    "\n",
    "for doc in range(0,len(documents)):\n",
    "    word=[]\n",
    "    z=unicode(documents[doc])\n",
    "    for a in jieba.cut(z):\n",
    "        if not a in stoplist:\n",
    "            ab=[a]\n",
    "            word+=ab\n",
    "            \n",
    "    #print word\n",
    "    words+=[word]\n",
    "model = w2v(words, min_count=1, size=400)\n",
    "\n",
    "tEnd = time.time() #記時(時間結束)\n",
    "print ' 花了 {} s'.format(tEnd-tStart)    #將經過時間print 出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金融卡\n",
      "持卡人\n",
      "發卡\n",
      "刷卡\n",
      "Visa\n",
      "轉帳\n",
      "刷爆\n",
      "儲值\n",
      "悠遊聯名卡\n",
      "網路銀行\n",
      "收單\n",
      "美國運通\n",
      "門號\n",
      "卡號\n",
      "提款\n",
      "ATM\n",
      "VISA\n",
      "掛失\n",
      "盜刷\n",
      "存簿\n",
      "支付寶\n",
      "簽帳\n",
      "綁定\n",
      "靜止戶\n",
      "SIM卡\n",
      "MasterCard\n",
      "電子錢包\n",
      "匯款\n",
      "提款卡\n",
      "辦卡\n",
      "臨櫃\n",
      "該行\n",
      "銀聯卡\n",
      "旅行支票\n",
      "會員卡\n",
      "銀行帳戶\n",
      "網路購物\n",
      "外幣\n",
      "行動支付\n",
      "萬事達卡\n",
      "晶片卡\n",
      "預付卡\n",
      "自動加值\n",
      "手機門號\n",
      "聯名卡\n",
      "遊戲點數\n",
      "簽單\n",
      "免手續費\n",
      "美國運通卡\n",
      "讀卡機\n"
     ]
    }
   ],
   "source": [
    "similar=model.most_similar(u'',topn=50)\n",
    "for a in similar:\n",
    "    print a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存檔  規定要存兩個\n",
    "\n",
    "outp1=open('C:/Users/BIG DATA/Desktop/model','a+')\n",
    "outp2=open('C:/Users/BIG DATA/Desktop/model_vec','w')\n",
    "\n",
    "model.save(outp1)\n",
    "model.save_word2vec_format(outp2, binary=False)\n",
    "outp1.close()\n",
    "outp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "could not find MARK",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-49855f5d4951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/BIG DATA/Desktop/model_vec\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\BIG DATA\\Anaconda2\\lib\\site-packages\\gensim\\models\\word2vec.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1486\u001b[0m         \u001b[1;31m# update older models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'table'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BIG DATA\\Anaconda2\\lib\\site-packages\\gensim\\utils.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BIG DATA\\Anaconda2\\lib\\site-packages\\gensim\\utils.pyc\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[1;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: could not find MARK"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec.load(\"C:/Users/BIG DATA/Desktop/model_vec\")  #讀取model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
