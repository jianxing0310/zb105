{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "Loading model cost 0.545 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.545 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pymongo import MongoClient \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "jieba.set_dictionary('E:/text_mining/dict.txt')  #切換至中文繁體字庫\n",
    "jieba.load_userdict('E:/text_mining/dict_keyw.txt')  #\n",
    "jieba.load_userdict('E:/text_mining/dict_cbdic.txt')  #\n",
    "#預設就是自己\n",
    "client = MongoClient('10.120.28.14',27017)  #不用修改  字典檔請改位子\n",
    "#client = MongoClient('localhost:27017')  #不用修改  字典檔請改位子\n",
    "\n",
    "database = client['ptt1']\n",
    "collection =database['hatsix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23486\n"
     ]
    }
   ],
   "source": [
    " a=collection.find()\n",
    "print a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14421\n"
     ]
    }
   ],
   "source": [
    " a=collection.find({\"date\":{\"$regex\":\"20160\"}})\n",
    "print a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成 14421 筆\n",
      " 花了 106.335999966 s\n",
      "完成 5166 筆\n",
      " 花了 65.3529999256 s\n",
      "完成 3899 筆\n",
      " 花了 59.246999979 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIG DATA\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:28: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for ii in range (1,4):   # 1-9月    10月後改為10-13再執行\n",
    "    a=collection.find({\"date\":{\"$regex\":\"20160{}\".format(ii)}}).count()    \n",
    "    content =[]\n",
    "    tStart=time.time() #計算所需時間(計時開始)\n",
    "    \n",
    "    for post in collection.find({\"date\":{\"$regex\":\"20160{}\".format(ii)}}): \n",
    "        summary = post['content']\n",
    "        content.append('/'.join(jieba.cut(summary)))\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(content)  # titile 放文本\n",
    "    weight = X.toarray()\n",
    "    features = vectorizer.get_feature_names()     # 拿到所有的關鍵詞  \n",
    "\n",
    "    top_features = []\n",
    "    for n in range(0,a):  #迴圈參考上面的總文章數\n",
    "        indices = np.argsort(weight[n])[::-1]  # transformer = TfidfTransformer()  #X.toarray()[5] 是第幾篇新聞的意思\n",
    "        # 看TOP多少的詞\n",
    "        top_n = 40\n",
    "        top_features.append([features[i] for i in indices[:top_n]])    #這邊的寫法會讓關鍵字中間會有空白     \n",
    "\n",
    "    obj=collection.find({\"date\":{\"$regex\":\"20160{}\".format(ii)}})\n",
    "    for i in range(0,a):  #迴圈參考上面的總文章數\n",
    "        collection.update({\"_id\":obj[i][\"_id\"]},{\"$set\":{\"tfidf\":top_features[i]}}) #collection.update即可\n",
    "\n",
    "    tEnd = time.time() #記時(時間結束)\n",
    "    print '完成',len(top_features),'筆'    \n",
    "\n",
    "    \n",
    "    \n",
    "    del content[:]  #清除list暫存記憶體\n",
    "    del top_features[:]  #清除list暫存記憶體\n",
    "    \n",
    "    print ' 花了 {} s'.format(tEnd-tStart)    #將經過時間print 出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成 13197 筆\n",
      " 花了 132.322000027 s\n",
      "完成 17676 筆\n",
      " 花了 441.588000059 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIG DATA\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:30: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import time\n",
    "for aa in range(1,4):\n",
    "    for ii in range (1,2):   # 1-9月    10月後改為10-13再執行\n",
    "        a=collection.find({\"date\":{\"$regex\":\"20160{}{}\".format(ii,aa)}}).count()\n",
    "        content =[]\n",
    "        tStart=time.time() #計算所需時間(計時開始)\n",
    "        if a ==0:\n",
    "            print \"20160{}{}\".format(aa,ii)\n",
    "        else:\n",
    "            for post in collection.find({\"date\":{\"$regex\":\"20160{}{}\".format(ii,aa)}}):\n",
    "                summary = post['content']\n",
    "                content.append('/'.join(jieba.cut(summary)))\n",
    "\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            X = vectorizer.fit_transform(content)  # titile 放文本\n",
    "            weight = X.toarray()\n",
    "            features = vectorizer.get_feature_names()     # 拿到所有的關鍵詞  \n",
    "\n",
    "            top_features = []\n",
    "            for n in range(0,a):  #迴圈參考上面的總文章數\n",
    "                indices = np.argsort(weight[n])[::-1]  # transformer = TfidfTransformer()  #X.toarray()[5] 是第幾篇新聞的意思\n",
    "                # 看TOP多少的詞\n",
    "                top_n = 40\n",
    "                top_features.append([features[i] for i in indices[:top_n]])    #這邊的寫法會讓關鍵字中間會有空白     \n",
    "\n",
    "            obj=collection.find({\"date\":{\"$regex\":\"20160{}{}\".format(ii,aa)}})\n",
    "            for i in range(0,a):  #迴圈參考上面的總文章數\n",
    "                collection.update({\"_id\":obj[i][\"_id\"]},{\"$set\":{\"tfidf\":top_features[i]}}) #collection.update即可\n",
    "\n",
    "            tEnd = time.time() #記時(時間結束)\n",
    "            print '完成',len(top_features),'筆'    \n",
    "\n",
    "            del content[:]  #清除list暫存記憶體\n",
    "            del top_features[:]  #清除list暫存記憶體\n",
    "\n",
    "            print ' 花了 {} s'.format(tEnd-tStart)    #將經過時間print 出來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "Loading model cost 0.556 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.556 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8397\n",
      "8086\n",
      "8527\n",
      "8810\n",
      "9048\n",
      "8816\n",
      "8170\n",
      "8220\n",
      "9477\n",
      "8264\n",
      "7643\n",
      "8637\n",
      "8534\n",
      "8795\n",
      "8452\n",
      "8810\n",
      "8091\n",
      "3406\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pymongo import MongoClient \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "jieba.set_dictionary('E:/text_mining/dict.txt')  #切換至中文繁體字庫\n",
    "jieba.load_userdict('E:/text_mining/dict_keyw.txt')  #\n",
    "jieba.load_userdict('E:/text_mining/dict_cbdic.txt')  #\n",
    "#預設就是自己\n",
    "client = MongoClient('10.120.28.14',27017)  #不用修改  字典檔請改位子\n",
    "#client = MongoClient('localhost:27017')  #不用修改  字典檔請改位子\n",
    "\n",
    "for i in xrange(1,19):\n",
    "    database = client['ptt1']\n",
    "    collection =database['goss2016_{}'.format(i)]\n",
    "    a=collection.find()\n",
    "    print a.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from E:\\text_mining\\dict.txt ...\n",
      "Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdat~1\\appdata\\local\\temp\\jieba.u144803eaa96482ea338b54ad8c7f9634.cache\n",
      "Loading model cost 0.502 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.502 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成 8050 筆\n",
      " 花了 36.1100001335 s\n",
      "完成 8676 筆\n",
      " 花了 57.2769999504 s\n",
      "完成 8471 筆\n",
      " 花了 39.8510000706 s\n",
      "完成 8468 筆\n",
      " 花了 37.9210000038 s\n",
      "完成 8401 筆\n",
      " 花了 39.2920000553 s\n",
      "完成 8736 筆\n",
      " 花了 40.9279999733 s\n",
      "完成 8635 筆\n",
      " 花了 38.9260001183 s\n",
      "完成 8857 筆\n",
      " 花了 40.7569999695 s\n",
      "完成 8761 筆\n",
      " 花了 40.5759999752 s\n",
      "完成 7192 筆\n",
      " 花了 30.2129998207 s\n",
      "完成 6150 筆\n",
      " 花了 24.6719999313 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIG DATA\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:41: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from pymongo import MongoClient \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('E:/text_mining/dict.txt')  #切換至中文繁體字庫\n",
    "jieba.load_userdict('E:/text_mining/dict_keyw_new.txt')  #\n",
    "#jieba.load_userdict('E:/text_mining/dict_cbdic.txt')  #\n",
    "#預設就是自己\n",
    "client = MongoClient()  #不用修改  字典檔請改位子\n",
    "#client = MongoClient('localhost:27017')  #不用修改  字典檔請改位子\n",
    "\n",
    "for i in xrange(1,12):\n",
    "    database = client['ptt2']\n",
    "    collection =database['ptt{}'.format(i)]\n",
    "    a=collection.find().count()\n",
    "    \n",
    "    content =[]\n",
    "    tStart=time.time() #計算所需時間(計時開始)    \n",
    "    for post in collection.find():\n",
    "        summary = post['content']\n",
    "        content.append('/'.join(jieba.cut(summary)))\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(content)  # titile 放文本\n",
    "    weight = X.toarray()\n",
    "    features = vectorizer.get_feature_names()     # 拿到所有的關鍵詞  \n",
    "\n",
    "    top_features = []\n",
    "    for n in range(0,a):  #迴圈參考上面的總文章數\n",
    "        indices = np.argsort(weight[n])[::-1]  # transformer = TfidfTransformer()  #X.toarray()[5] 是第幾篇新聞的意思\n",
    "        # 看TOP多少的詞\n",
    "        top_n = 40\n",
    "        top_features.append([features[i] for i in indices[:top_n]])    #這邊的寫法會讓關鍵字中間會有空白     \n",
    "\n",
    "    obj=collection.find()\n",
    "    for z in range(0,a):  #迴圈參考上面的總文章數\n",
    "        collection.update({\"_id\":obj[z][\"_id\"]},{\"$set\":{\"tfidf\":top_features[z]}}) #collection.update即可\n",
    "\n",
    "    tEnd = time.time() #記時(時間結束)\n",
    "    print '完成',len(top_features),'筆'    \n",
    "\n",
    "    del content[:]  #清除list暫存記憶體\n",
    "    del top_features[:]  #清除list暫存記憶體\n",
    "\n",
    "    print ' 花了 {} s'.format(tEnd-tStart)    #將經過時間print 出來\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
